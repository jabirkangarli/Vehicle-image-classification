{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aGEEGekmPDh_"
      },
      "outputs": [],
      "source": [
        "#@title requirements.txt\n",
        "%%writefile requirements.txt\n",
        "\n",
        "streamlit\n",
        "transformers\n",
        "torch\n",
        "Pillow\n",
        "numpy"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title install\n",
        "!pip install -q -r requirements.txt"
      ],
      "metadata": {
        "id": "981TFijXPSRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title app.py version 0.1\n",
        "%%writefile app.py\n",
        "\n",
        "\n",
        "\n",
        "# imports\n",
        "\n",
        "from transformers import FlavaModel, BertTokenizer, FlavaFeatureExtractor\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import streamlit as st\n",
        "\n",
        "st.header('Image Classification')\n",
        "\n",
        "model = FlavaModel.from_pretrained(\"facebook/flava-full\")\n",
        "model.eval()\n",
        "fe = FlavaFeatureExtractor.from_pretrained(\"facebook/flava-full\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"facebook/flava-full\")\n",
        "\n",
        "\n",
        "\n",
        "def load_image(image_file):\n",
        "\timg = Image.open(image_file)\n",
        "\treturn img\n",
        "\n",
        "\n",
        "def shot2(img, labels_text):\n",
        "    # im = img\n",
        "    PIL_image = np.asarray(img)\n",
        "\n",
        "    # PIL_image = Image.fromarray(np.uint8(image)).convert('RGB')\n",
        "    labels = labels_text.split(\",\")\n",
        "    label_with_template = [f\"This is a photo of a {label}\" for label in labels]\n",
        "    image_input = fe([PIL_image], return_tensors=\"pt\")\n",
        "    text_inputs = tokenizer(label_with_template, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "    image_embeddings = model.get_image_features(**image_input)[:, 0, :]\n",
        "    text_embeddings = model.get_text_features(**text_inputs)[:, 0, :]\n",
        "    similarities = list(torch.nn.functional.softmax((text_embeddings @ image_embeddings.T).squeeze(0), dim=0))\n",
        "    res =  {label: similarities[idx].item() for idx, label in enumerate(labels)}\n",
        "\n",
        "    # res = shot2('/content/71xkI-PIE5L._SL1500_.jpg', 'car, not car, baby, fruit, vegetable, building')\n",
        "    return max(res, key=res.get)\n",
        "\n",
        "\n",
        "image_file = st.sidebar.file_uploader(\"Upload Images\", type=[\"png\",\"jpg\",\"jpeg\"])\n",
        "\n",
        "with st.sidebar.expander(''):\n",
        "    possible_labels = st.text_area('Possible labels:', 'car, map, not car, baby, fruit, vegetable, building')\n",
        "\n",
        "if image_file is not None:\n",
        "\n",
        "        # To See details\n",
        "        file_details = {\"filename\":image_file.name, \"filetype\":image_file.type,\n",
        "                        \"filesize\":image_file.size}\n",
        "        with st.expander('Show picture details'):\n",
        "            st.write(file_details)\n",
        "\n",
        "        # To View Uploaded Image\n",
        "        st.header('Show picture and predict label')\n",
        "        with st.spinner():\n",
        "            st.image(load_image(image_file),width=250)\n",
        "            picture = load_image(image_file)\n",
        "            detected_name = shot2(picture, possible_labels)\n",
        "            if 'car' in str(detected_name).lower():\n",
        "                label = 'vehicle'\n",
        "                st.success(label)\n",
        "            else:\n",
        "                label = 'non-vehicle'\n",
        "                st.error(label)\n",
        "\n",
        "                with st.expander('Show what can be on the pic'):\n",
        "                    st.info(detected_name)"
      ],
      "metadata": {
        "id": "_YuLiRI_V7Ee",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%writefile app.py\n",
        "#@title app.py version 0.2\n",
        "\n",
        "\n",
        "# imports\n",
        "\n",
        "from transformers import FlavaModel, BertTokenizer, FlavaFeatureExtractor\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "import torch\n",
        "import streamlit as st\n",
        "\n",
        "st.header('Image Classification')\n",
        "\n",
        "model = FlavaModel.from_pretrained(\"facebook/flava-full\")\n",
        "model.eval()\n",
        "fe = FlavaFeatureExtractor.from_pretrained(\"facebook/flava-full\")\n",
        "tokenizer = BertTokenizer.from_pretrained(\"facebook/flava-full\")\n",
        "\n",
        "\n",
        "\n",
        "def load_image(image_file):\n",
        "\timg = Image.open(image_file)\n",
        "\treturn img\n",
        "\n",
        "@st.cache()\n",
        "def predict(img, labels_text):\n",
        "    # im = img\n",
        "    PIL_image = np.asarray(img)\n",
        "\n",
        "    # PIL_image = Image.fromarray(np.uint8(image)).convert('RGB')\n",
        "    labels = labels_text.split(\",\")\n",
        "    label_with_template = [f\"This is a photo of a {label}\" for label in labels]\n",
        "    image_input = fe([PIL_image], return_tensors=\"pt\")\n",
        "    text_inputs = tokenizer(label_with_template, padding=\"max_length\", return_tensors=\"pt\")\n",
        "\n",
        "    image_embeddings = model.get_image_features(**image_input)[:, 0, :]\n",
        "    text_embeddings = model.get_text_features(**text_inputs)[:, 0, :]\n",
        "    similarities = list(torch.nn.functional.softmax((text_embeddings @ image_embeddings.T).squeeze(0), dim=0))\n",
        "    res =  {label: similarities[idx].item() for idx, label in enumerate(labels)}\n",
        "\n",
        "    # res = shot2('/content/71xkI-PIE5L._SL1500_.jpg', 'car, not car, baby, fruit, vegetable, building')\n",
        "    return max(res, key=res.get).replace(' ', '')\n",
        "\n",
        "\n",
        "image_file = st.sidebar.file_uploader(\"Upload Images\", type=[\"png\",\"jpg\",\"jpeg\"])\n",
        "\n",
        "with st.sidebar.expander(''):\n",
        "    possible_labels = st.text_area('Possible labels:', 'map, baby, fruit, vegetable, building, person, furniture, tree, sea')\n",
        "    target_labels = st.text_area('Vehicle-related words:', 'bus, limousine, pickup, SUV, sedan')\n",
        "    target_labels_list =  target_labels.split(', ')\n",
        "    \n",
        "    possible_labels = str(set(possible_labels.split(',') + target_labels.split(',')) ).replace('  ', ' ').replace(\"'\", \"\").replace('{', '').replace('}', '')\n",
        "\n",
        "\n",
        "if image_file is not None:\n",
        "\n",
        "    # To See details\n",
        "    file_details = {\"filename\":image_file.name, \"filetype\":image_file.type,\n",
        "                    \"filesize\":image_file.size}\n",
        "    with st.expander('Show picture details'):\n",
        "        st.write(file_details)\n",
        "\n",
        "    # To View Uploaded Image\n",
        "    st.header('Show picture and predict label')\n",
        "\n",
        "    st.image(load_image(image_file),width=250)\n",
        "    picture = load_image(image_file)\n",
        "    detected_name = predict(picture, possible_labels)\n",
        "\n",
        "\n",
        "    if str(detected_name) in str(target_labels_list):\n",
        "        label = 'vehicle'\n",
        "        st.success(label)\n",
        "        with st.expander('Show what kind of vehicle it can be'):\n",
        "            st.info(detected_name)\n",
        "    else:\n",
        "        label = 'non-vehicle'\n",
        "        st.error(label)\n",
        "        with st.expander('Show what can be on the pic'):\n",
        "            st.info(detected_name)\n",
        "\n",
        "\n",
        "        with st.expander('Show what can be on the pic'):\n",
        "            st.info(detected_name)\n"
      ],
      "metadata": {
        "id": "waY5OOqpaUbe",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Generate link to web application\n",
        "\n",
        "! streamlit run app.py & npx localtunnel --port 8501 "
      ],
      "metadata": {
        "cellView": "form",
        "id": "f6CDA-BnPVOs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}